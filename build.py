import os
import json
import shutil
import markdown
import requests
from pathlib import Path
from bs4 import BeautifulSoup
from jinja2 import Environment, FileSystemLoader

# ===============================
# è¨­å®š
# ===============================
ARTICLES_FILE = "articles.json"
BLOG_FILE = "data/blog.json"
TEMPLATES_DIR = "templates"
STATIC_DIR = "static"
DIST_DIR = "dist"
PORTFOLIO_DIST = f"{DIST_DIR}/portfolio"
BLOG_DIST = f"{DIST_DIR}/blog"
STATIC_DIST = f"{DIST_DIR}/static"


# ===============================
# ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
# ===============================

def fetch_og_image(url: str) -> str | None:
    """æŒ‡å®š URL ã® OGP ç”»åƒã‚’å–å¾—"""
    try:
        res = requests.get(url, timeout=8, headers={"User-Agent": "Mozilla/5.0"})
        soup = BeautifulSoup(res.text, "html.parser")
        og = soup.find("meta", property="og:image")
        if og: return og.get("content")
        tw = soup.find("meta", attrs={"name": "twitter:image"})
        if tw: return tw.get("content")
        return None
    except:
        return None


def load_markdown_files():
    """data/blog.json ã‚’èª­ã¿è¾¼ã¿ã€æŒ‡å®šã•ã‚ŒãŸãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ã‚’ HTML ã«å¤‰æ›"""
    posts = []
    
    if not os.path.exists(BLOG_FILE):
        print(f"Warning: {BLOG_FILE} not found.")
        return []

    with open(BLOG_FILE, "r", encoding="utf-8") as f:
        blog_data = json.load(f)

    for entry in blog_data:
        md_path = entry.get("markdown")
        if not md_path or not os.path.exists(md_path):
            print(f"Warning: Markdown file not found: {md_path}")
            continue

        with open(md_path, "r", encoding="utf-8") as f:
            body_md = f.read()

        body_html = markdown.markdown(body_md, extensions=["fenced_code"])

        slug = entry.get("slug")
        html_path = f"{BLOG_DIST}/{slug}.html"

        post = {
            "title": entry.get("title", slug),
            "date": entry.get("date", ""),
            "tags": entry.get("tags", []),
            "summary": entry.get("summary", body_md[:120]),
            "slug": slug,
            "html_path": html_path,
            "html": body_html,
            "cover": entry.get("cover")
        }
        posts.append(post)

    return posts


def ensure_cover_images(portfolio):
    """ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã® OGP ç”»åƒã‚’è‡ªå‹•å–å¾—"""
    updated = False
    for item in portfolio:
        if "cover" not in item or not item["cover"]:
            print(f"[OGP] Fetching: {item['url']}")
            img = fetch_og_image(item["url"])
            if img:
                item["cover"] = img
                updated = True
    return portfolio, updated


# ===============================
# ãƒ“ãƒ«ãƒ‰å‡¦ç†
# ===============================

def main():
    # dist åˆæœŸåŒ–
    os.makedirs(DIST_DIR, exist_ok=True)
    os.makedirs(PORTFOLIO_DIST, exist_ok=True)
    os.makedirs(BLOG_DIST, exist_ok=True)

    env = Environment(loader=FileSystemLoader(TEMPLATES_DIR), autoescape=True)

    # articles.json èª­ã¿è¾¼ã¿
    with open(ARTICLES_FILE, "r", encoding="utf-8") as f:
        portfolio_data = json.load(f)

    # ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ª OGP æ›´æ–°
    portfolio_data, updated = ensure_cover_images(portfolio_data)
    if updated:
        with open(ARTICLES_FILE, "w", encoding="utf-8") as f:
            json.dump(portfolio_data, f, indent=2, ensure_ascii=False)
        print("âœ¨ Updated OGP images in articles.json")

    # ãƒ–ãƒ­ã‚°è¨˜äº‹èª­ã¿è¾¼ã¿
    blog_posts = load_markdown_files()

    # ã‚¿ã‚°åˆ¥è¾æ›¸ï¼ˆãƒ–ãƒ­ã‚°+ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªå…±é€šï¼‰
    tag_map = {}
    for p in blog_posts:
        for t in p["tags"]:
            tag_map.setdefault(t, []).append(p)
    for p in portfolio_data:
        for t in p["tags"]:
            tag_map.setdefault(t, []).append(p)

    # ===============================
    # ãƒ–ãƒ­ã‚°è¨˜äº‹ã‚’ç”Ÿæˆ
    # ===============================
    tpl_blog = env.get_template("blog_post.html")

    for p in blog_posts:
        html = tpl_blog.render(
            article=p,
            title=p["title"],
            keywords=",".join(p["tags"]),
            description=p["summary"]
        )
        with open(p["html_path"], "w", encoding="utf-8") as f:
            f.write(html)

    # ===============================
    # ãƒ–ãƒ­ã‚° TOP
    # ===============================
    tpl_index = env.get_template("index.html")
    html = tpl_index.render(
        articles=blog_posts,
        title="ãƒ–ãƒ­ã‚°",
        description="æœ€æ–°ã®ãƒ–ãƒ­ã‚°è¨˜äº‹",
        keywords="ãƒ–ãƒ­ã‚°,è¨˜äº‹"
    )
    with open(f"{DIST_DIR}/index.html", "w", encoding="utf-8") as f:
        f.write(html)

    # ===============================
    # ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ª TOP
    # ===============================
    tpl_pf = env.get_template("portfolio_index.html")
    html = tpl_pf.render(
        articles=portfolio_data,
        title="ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ª",
        description="åˆ¶ä½œå®Ÿç¸¾ä¸€è¦§",
        keywords="ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ª,åˆ¶ä½œ"
    )
    with open(f"{PORTFOLIO_DIST}/index.html", "w", encoding="utf-8") as f:
        f.write(html)

    # ===============================
    # ã‚¿ã‚°ãƒšãƒ¼ã‚¸ç”Ÿæˆ
    # ===============================
    tpl_tag = env.get_template("tag.html")

    TAG_DIST = f"{DIST_DIR}/tag"
    os.makedirs(TAG_DIST, exist_ok=True)

    for tag, items in tag_map.items():
        html = tpl_tag.render(
            tag=tag,
            articles=items,
            title=f"{tag} ã®è¨˜äº‹",
            description=f"{tag} ã«é–¢ã™ã‚‹è¨˜äº‹ä¸€è¦§",
            keywords=tag
        )
        with open(f"{TAG_DIST}/{tag}.html", "w", encoding="utf-8") as f:
            f.write(html)

    # ===============================
    # é™çš„ãƒ•ã‚¡ã‚¤ãƒ«ã‚³ãƒ”ãƒ¼
    # ===============================
    if os.path.exists(STATIC_DIR):
        if os.path.exists(STATIC_DIST):
            shutil.rmtree(STATIC_DIST)
        shutil.copytree(STATIC_DIR, STATIC_DIST)
        print("ğŸ“¦ Static files copied")

    print("ğŸ‰ ãƒ“ãƒ«ãƒ‰å®Œäº†!")


if __name__ == "__main__":
    main()
